{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FrameworkForFastFeatureExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsoGkDk3Ct/elEm0xnRbV7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmitNaikRepository/kaggle_best_practices/blob/master/FrameworkForFastFeatureExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx14YWwrdX-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from tqdm import tqdm \n",
        "from joblib import Parallel, delayed \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCA3s6OdOj2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lets make a class \n",
        "class FeatureGenerator(object):\n",
        "  def __init__(self,dtype,n_jobs=1,chunk_size=None):\n",
        "    self.dtype=dtype\n",
        "    self.filename=filename\n",
        "    self.n_jobs=n_jobs\n",
        "    self.chunk_size=chunk_size\n",
        "    self.test_file=test_file\n",
        "    if self.dtype =='train':\n",
        "      self.filename='../input/train.csv'\n",
        "      self.total_data=int(45642163/self.chunk_size)\n",
        "    else:\n",
        "      submission=pd.read_csv('../input/main/data/data.csv')\n",
        "      for seg_id in submission.seg_id.values:\n",
        "        self.filename.append((seg_id,'../input/train.csv'+seg_id+'.csv'))\n",
        "        self.total_filename=int(len(submission))\n",
        "\n",
        "  def read_chunk(self):\n",
        "    if self.type=='train':\n",
        "      inter_df=pd.read_csv(self.filename,iterator=True,chunksize=self.chunk_size,dtype={'acoustic_data':np.float64,'time_to_failure':np.float64})\n",
        "      for counter ,df in enumurate(iter_df):\n",
        "        x=df.acoustic_data.values\n",
        "        y=df.time_to_failure.clues[-1]\n",
        "        seg_id='train_'+str(counter)\n",
        "        yield seg_id,x,y\n",
        "      else:\n",
        "        for seg_id,f in self.test_files:\n",
        "          df=pd.read_csv(f,dtype={'acoustic_Data':np.float64})\n",
        "          x=df.acoustics_data.values\n",
        "          yield seg_id,x,-999\n",
        "      def feature(self,x,y,seg_id):\n",
        "        feature_dict=dict()\n",
        "        feature_dict['target']=y\n",
        "        feature_dict['seg_id']=seg_id\n",
        "\n",
        "        #create feature here \n",
        "        #lets take an example\n",
        "        #feature_dict['mean]=np.mean(x)\n",
        "\n",
        "        return feature_dict\n",
        "\n",
        "      def generate(self):\n",
        "        feature_list=[]\n",
        "        res=Parallel(n_jobs=self.n_jobs,backend='threading')\n",
        "      (delayed(self.features)(x,y,s)\n",
        "      for s,x,y in tqdm(self.read_chunks(),total=self.total_data)):\n",
        "      total=self.total_data))\n",
        "      for r in res:\n",
        "        feature_list.append(r)\n",
        "        return pd.DataFrame(feature_list)\n",
        "\n",
        "      training_fg=FeatureGenerator(dtype='train',n_jobs=4,chunk_size=15000)\n",
        "      )\n",
        "      training_data=training_fg.generate()\n",
        "\n",
        "      training_data.to_csv(\"../input/train_feaures.csv\",index=False)\n",
        "      test_data.to_csv(\"../input/test_feature.csv\",index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}